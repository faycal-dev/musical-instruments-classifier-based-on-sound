{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# the dataset link\n# https://www.kaggle.com/hosseinmousavi/pcmir-database","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-01T21:19:51.546917Z","iopub.execute_input":"2021-10-01T21:19:51.547225Z","iopub.status.idle":"2021-10-01T21:19:51.553417Z","shell.execute_reply.started":"2021-10-01T21:19:51.547192Z","shell.execute_reply":"2021-10-01T21:19:51.552697Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport IPython.display as ipd\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# to have a clean notebook\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:52.826438Z","iopub.execute_input":"2021-10-01T21:19:52.827044Z","iopub.status.idle":"2021-10-01T21:19:53.912255Z","shell.execute_reply.started":"2021-10-01T21:19:52.827005Z","shell.execute_reply":"2021-10-01T21:19:53.911462Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# librosa is a tool to read audio files and transform it to waves\ntest_filename='../input/pcmir-database/Persian Classical Music Instrument Recognition (PCMIR) Database/Ney/Ney (10).mp3'\nplt.figure(figsize=(14,5))\n# the sample rate is the nbr of samples of audio we take in a seconde by default it is 22 khz \ndata,sample_rate=librosa.load(test_filename)\nlibrosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(test_filename)\n# all files are 5s length","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:54.981838Z","iopub.execute_input":"2021-10-01T21:19:54.982497Z","iopub.status.idle":"2021-10-01T21:19:56.370037Z","shell.execute_reply.started":"2021-10-01T21:19:54.982460Z","shell.execute_reply":"2021-10-01T21:19:56.369303Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data,sample_rate","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:56.371864Z","iopub.execute_input":"2021-10-01T21:19:56.372076Z","iopub.status.idle":"2021-10-01T21:19:56.379071Z","shell.execute_reply.started":"2021-10-01T21:19:56.372050Z","shell.execute_reply":"2021-10-01T21:19:56.378366Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# we can also read audio files with scipy\n# from scipy.io import wavfile as wav\n# wave_sample_rate, wave_audio=wav.read(test_filename)\n# but the values will not be normlized between 0 and 1 and it can bee in 2 channels librosa does all this work for us so we will use it","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:56.505141Z","iopub.execute_input":"2021-10-01T21:19:56.505626Z","iopub.status.idle":"2021-10-01T21:19:56.508788Z","shell.execute_reply.started":"2021-10-01T21:19:56.505595Z","shell.execute_reply":"2021-10-01T21:19:56.508095Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<h3>this waveform for the audio doesn't give us that much of information for the classification so we need to do a bunch of operations on it to become ready for the model</h3>","metadata":{}},{"cell_type":"markdown","source":"<h1>1- fast fourier transform</h1>","metadata":{}},{"cell_type":"code","source":"fft = np.fft.fft(data)\n\n# calculate abs value to get magnitude\nspectrum = np.abs(fft)\n\n# create frequency variable\nf = np.linspace(0, sample_rate, len(spectrum))\n\n# take half of the spectrum and frequency because with the fft we will get a mirror diagram so we take only the half \nleft_spectrum = spectrum[:int(len(spectrum)/2)]\nleft_f = f[:int(len(spectrum)/2)]\n\n# plot spectrum\nplt.figure(figsize=(14,5))\nplt.plot(left_f, left_spectrum, alpha=0.4)\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Magnitude\")\nplt.title(\"Power spectrum\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:58.116530Z","iopub.execute_input":"2021-10-01T21:19:58.116814Z","iopub.status.idle":"2021-10-01T21:19:58.379122Z","shell.execute_reply.started":"2021-10-01T21:19:58.116785Z","shell.execute_reply":"2021-10-01T21:19:58.378336Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<h3>here we moved from amplitude in function of time to frequency which is better and gives us more informations but still it is static because we lost the information of time .... for this we will apply the stft (apply many fft on short times so we can have all the info needed in on spectrogram)</h3>","metadata":{}},{"cell_type":"code","source":"hop_length = 512 # how many sample we move between each step\nn_fft = 2048 # how many samples to take for each fft step\n\n# perform stft\nstft = librosa.stft(data, n_fft=n_fft, hop_length=hop_length)\n\n# calculate abs value to get magnitude\nspectrogram = np.abs(stft)\n\n# display spectrogram\nplt.figure(figsize=(14,5))\nlibrosa.display.specshow(spectrogram, sr=sample_rate, hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Frequency\")\nplt.colorbar()\nplt.title(\"Spectrogram\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:58.543681Z","iopub.execute_input":"2021-10-01T21:19:58.544273Z","iopub.status.idle":"2021-10-01T21:19:58.965945Z","shell.execute_reply.started":"2021-10-01T21:19:58.544240Z","shell.execute_reply":"2021-10-01T21:19:58.965157Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<h3> here we have a spectrogram wich represent the magnitude and frequency in the time but its not that obvious so we will apply logarithm to cast from amplitude to Decibels</h3>","metadata":{}},{"cell_type":"code","source":"log_spectrogram = librosa.amplitude_to_db(spectrogram)\nplt.figure(figsize=(14,5))\nlibrosa.display.specshow(log_spectrogram, sr=sample_rate, hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Frequency\")\nplt.colorbar()\nplt.title(\"Spectrogram\")\n# here we see that the energy of the notes (red) is in the low frequencys all the 5s","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:58.967437Z","iopub.execute_input":"2021-10-01T21:19:58.967797Z","iopub.status.idle":"2021-10-01T21:19:59.650200Z","shell.execute_reply.started":"2021-10-01T21:19:58.967758Z","shell.execute_reply":"2021-10-01T21:19:59.647958Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<h3>since nothing is perfect.. the problem with this spectrogram is that if we apply the same notes with diffrent instruments (guitar and violin) it will give us a pretty similar spectrograme which is problem for classification.. and for this the solution is to use mfcc </h3>","metadata":{}},{"cell_type":"code","source":"MFCCs = librosa.feature.mfcc(data, sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n# generally n_mfcc is between 13 and 40\n# display MFCCs\nplt.figure(figsize=(14,5))\nlibrosa.display.specshow(MFCCs, sr=sample_rate, hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"MFCC coefficients\")\nplt.colorbar()\nplt.title(\"MFCCs\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:59.652001Z","iopub.execute_input":"2021-10-01T21:19:59.652278Z","iopub.status.idle":"2021-10-01T21:19:59.949167Z","shell.execute_reply.started":"2021-10-01T21:19:59.652243Z","shell.execute_reply":"2021-10-01T21:19:59.948504Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<h1>loading the data</h1>","metadata":{}},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\ndef read_data(dataset_path):\n    hop_length = 512 \n    n_fft = 2048 \n    x, x_mean, y = [],[],[]\n    classes = os.listdir(dataset_path)\n    classes.remove(\"ReadMe.txt\")\n    for classe in classes:\n        print(classe)\n        files = os.listdir(os.path.join(dataset_path,str(classe)))\n        for file in tqdm(files):\n            file_path = os.path.join(dataset_path,str(classe),str(file))\n            signal, sample_rate = librosa.load(file_path)\n            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n            # here we will use both of this values and see wich one is better \n            # i think the use of the transpose is for the shapes to be correct\n            mfcc = MFCCs.T\n            mfcc_mean = np.mean(MFCCs.T,axis=0)\n            x.append(mfcc)\n            x_mean.append(mfcc_mean)\n            y.append(classe)\n    y = np.array(pd.get_dummies(y))\n    return x, x_mean, y","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:59.950970Z","iopub.execute_input":"2021-10-01T21:19:59.951223Z","iopub.status.idle":"2021-10-01T21:19:59.960518Z","shell.execute_reply.started":"2021-10-01T21:19:59.951189Z","shell.execute_reply":"2021-10-01T21:19:59.959649Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"dataset_path=\"../input/pcmir-database/Persian Classical Music Instrument Recognition (PCMIR) Database\"\nx, x_mean, y = read_data(dataset_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:19:59.962066Z","iopub.execute_input":"2021-10-01T21:19:59.962332Z","iopub.status.idle":"2021-10-01T21:32:58.536888Z","shell.execute_reply.started":"2021-10-01T21:19:59.962297Z","shell.execute_reply":"2021-10-01T21:32:58.536027Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# sometimes the sound is bit more then 5s so the nfcc return a diffrent values\nmin_length = 238\nfor i in range(len(x)):\n    if (len(x[i]) < min_length):\n        min_length = len(x[i])\nfor i in range(len(x)):\n    x[i] = x[i][:min_length]","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:32:58.542353Z","iopub.execute_input":"2021-10-01T21:32:58.543130Z","iopub.status.idle":"2021-10-01T21:32:58.557873Z","shell.execute_reply.started":"2021-10-01T21:32:58.543078Z","shell.execute_reply":"2021-10-01T21:32:58.556864Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for i in range(len(x)):\n    if len(x[i]) != 219:\n        print(len(x[i]))","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:32:58.562586Z","iopub.execute_input":"2021-10-01T21:32:58.565981Z","iopub.status.idle":"2021-10-01T21:32:58.575131Z","shell.execute_reply.started":"2021-10-01T21:32:58.565933Z","shell.execute_reply":"2021-10-01T21:32:58.574187Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"<h1>ANN</h1>","metadata":{}},{"cell_type":"code","source":"print(f'the shape of x is {len(x),len(x[0]),len(x[0][0])}')\nprint(f'the shape of x_mean is {len(x_mean),len(x_mean[0])}')\nprint(f'the shape of y is {y.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:32:58.581044Z","iopub.execute_input":"2021-10-01T21:32:58.581490Z","iopub.status.idle":"2021-10-01T21:32:58.594938Z","shell.execute_reply.started":"2021-10-01T21:32:58.581438Z","shell.execute_reply":"2021-10-01T21:32:58.594092Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(np.array(x), y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:32:58.598231Z","iopub.execute_input":"2021-10-01T21:32:58.601445Z","iopub.status.idle":"2021-10-01T21:32:58.649683Z","shell.execute_reply.started":"2021-10-01T21:32:58.601403Z","shell.execute_reply":"2021-10-01T21:32:58.648922Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nimport tensorflow.keras as keras","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:32:58.652808Z","iopub.execute_input":"2021-10-01T21:32:58.653073Z","iopub.status.idle":"2021-10-01T21:32:58.657253Z","shell.execute_reply.started":"2021-10-01T21:32:58.653039Z","shell.execute_reply":"2021-10-01T21:32:58.656348Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# the kernel_regularizer and dropout are used to prevent over fitting\nmodel = Sequential()\nmodel.add(Flatten(input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(y.shape[1], activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:32:58.658780Z","iopub.execute_input":"2021-10-01T21:32:58.659049Z","iopub.status.idle":"2021-10-01T21:33:00.913796Z","shell.execute_reply.started":"2021-10-01T21:32:58.659016Z","shell.execute_reply":"2021-10-01T21:33:00.913070Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:00.915133Z","iopub.execute_input":"2021-10-01T21:33:00.915381Z","iopub.status.idle":"2021-10-01T21:33:00.932356Z","shell.execute_reply.started":"2021-10-01T21:33:00.915348Z","shell.execute_reply":"2021-10-01T21:33:00.931512Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=256, epochs=300)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:00.934728Z","iopub.execute_input":"2021-10-01T21:33:00.934988Z","iopub.status.idle":"2021-10-01T21:33:26.288305Z","shell.execute_reply.started":"2021-10-01T21:33:00.934955Z","shell.execute_reply":"2021-10-01T21:33:26.287637Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n    fig, axs = plt.subplots(2)\n\n    # create accuracy sublpot\n    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc=\"lower right\")\n    axs[0].set_title(\"Accuracy eval\")\n\n    # create error sublpot\n    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc=\"upper right\")\n    axs[1].set_title(\"Error eval\")\n\n    plt.show()\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:26.289691Z","iopub.execute_input":"2021-10-01T21:33:26.290209Z","iopub.status.idle":"2021-10-01T21:33:26.580170Z","shell.execute_reply.started":"2021-10-01T21:33:26.290169Z","shell.execute_reply":"2021-10-01T21:33:26.579529Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_train_mean, X_test_mean, y_train_mean, y_test_mean = train_test_split(np.array(x_mean), y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:26.581204Z","iopub.execute_input":"2021-10-01T21:33:26.581443Z","iopub.status.idle":"2021-10-01T21:33:26.590823Z","shell.execute_reply.started":"2021-10-01T21:33:26.581410Z","shell.execute_reply":"2021-10-01T21:33:26.590065Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(Dense(256, activation='relu',input_shape=(13,), kernel_regularizer=keras.regularizers.l2(0.001)))\nmodel2.add(Dropout(0.3))\nmodel2.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\nmodel2.add(Dropout(0.3))\nmodel2.add(Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\nmodel2.add(Dropout(0.3))\nmodel2.add(Dense(y.shape[1], activation=\"softmax\"))\nmodel2.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\nhistory2 = model2.fit(X_train_mean, y_train_mean, validation_data=(X_test_mean, y_test_mean), batch_size=256, epochs=300)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:26.592194Z","iopub.execute_input":"2021-10-01T21:33:26.592701Z","iopub.status.idle":"2021-10-01T21:33:47.063082Z","shell.execute_reply.started":"2021-10-01T21:33:26.592666Z","shell.execute_reply":"2021-10-01T21:33:47.062333Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# using the mean ann worked much better\nplot_history(history2)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:47.064609Z","iopub.execute_input":"2021-10-01T21:33:47.064875Z","iopub.status.idle":"2021-10-01T21:33:47.374392Z","shell.execute_reply.started":"2021-10-01T21:33:47.064831Z","shell.execute_reply":"2021-10-01T21:33:47.373701Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"<h1>lets use CNN</h1>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:47.375446Z","iopub.execute_input":"2021-10-01T21:33:47.375717Z","iopub.status.idle":"2021-10-01T21:33:47.380316Z","shell.execute_reply.started":"2021-10-01T21:33:47.375683Z","shell.execute_reply":"2021-10-01T21:33:47.379551Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# conv2d expects a 4d array\nX_train_cnn = X_train[..., np.newaxis]\nX_test_cnn = X_test[..., np.newaxis]\nX_train_cnn.shape,X_test_cnn.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:47.381707Z","iopub.execute_input":"2021-10-01T21:33:47.382143Z","iopub.status.idle":"2021-10-01T21:33:47.392186Z","shell.execute_reply.started":"2021-10-01T21:33:47.382109Z","shell.execute_reply":"2021-10-01T21:33:47.391324Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# batch normlization helps the model converge way faster\ncnn = Sequential()\n\n# 1 st covolution layer\ncnn.add(Conv2D(32, (3,3),activation='relu', input_shape=(X_train.shape[1], X_train.shape[2],1)))\ncnn.add(MaxPooling2D((3,3), strides=(2,2), padding='same'))\ncnn.add(BatchNormalization())\ncnn.add(Dropout(0.3))\n# 2 nd covolution layer\ncnn.add(Conv2D(32, (3,3),activation='relu', input_shape=(X_train.shape[1], X_train.shape[2],1)))\ncnn.add(MaxPooling2D((3,3), strides=(2,2), padding='same'))\ncnn.add(BatchNormalization())\ncnn.add(Dropout(0.3))\n# 3 rd covolution layer\ncnn.add(Conv2D(32, (2,2),activation='relu', input_shape=(X_train.shape[1], X_train.shape[2],1)))\ncnn.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\ncnn.add(BatchNormalization())\ncnn.add(Dropout(0.3))\n# ann layer\ncnn.add(Flatten())\ncnn.add(Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\ncnn.add(Dropout(0.3))\n\n# output\ncnn.add(Dense(y_train.shape[1], activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:47.393754Z","iopub.execute_input":"2021-10-01T21:33:47.394037Z","iopub.status.idle":"2021-10-01T21:33:47.501082Z","shell.execute_reply.started":"2021-10-01T21:33:47.393986Z","shell.execute_reply":"2021-10-01T21:33:47.500452Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"cnn.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\ncnn_history = cnn.fit(X_train_cnn, y_train, validation_data=(X_test_cnn, y_test), batch_size=256, epochs=200)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:33:47.502483Z","iopub.execute_input":"2021-10-01T21:33:47.502766Z","iopub.status.idle":"2021-10-01T21:34:21.354061Z","shell.execute_reply.started":"2021-10-01T21:33:47.502730Z","shell.execute_reply":"2021-10-01T21:34:21.353235Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"plot_history(cnn_history)\n# cnn is also doing very well and converge faster than ann with mfcc_mean","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:34:21.357905Z","iopub.execute_input":"2021-10-01T21:34:21.358114Z","iopub.status.idle":"2021-10-01T21:34:21.672871Z","shell.execute_reply.started":"2021-10-01T21:34:21.358086Z","shell.execute_reply":"2021-10-01T21:34:21.672198Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"<h1>lets try lstm</h1>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import LSTM,Bidirectional\nlstm = Sequential()\n\n# stack of 2 bidirectional sltm\nlstm.add(Bidirectional(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)))\nlstm.add(Bidirectional(LSTM(64)))\nlstm.add(Dropout(0.3))\n\n# dense layer with kernel regulizer and dropout to prevent overfitting\nlstm.add(Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\nlstm.add(Dropout(0.3))\n\n# output\nlstm.add(Dense(y_train.shape[1], activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:50:42.705320Z","iopub.execute_input":"2021-10-01T21:50:42.705618Z","iopub.status.idle":"2021-10-01T21:50:42.746536Z","shell.execute_reply.started":"2021-10-01T21:50:42.705586Z","shell.execute_reply":"2021-10-01T21:50:42.745867Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"lstm.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\nlstm_history = lstm.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=256, epochs=200)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:50:43.745476Z","iopub.execute_input":"2021-10-01T21:50:43.746206Z","iopub.status.idle":"2021-10-01T21:52:51.090242Z","shell.execute_reply.started":"2021-10-01T21:50:43.746165Z","shell.execute_reply":"2021-10-01T21:52:51.089541Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"plot_history(lstm_history)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T21:52:51.092159Z","iopub.execute_input":"2021-10-01T21:52:51.092509Z","iopub.status.idle":"2021-10-01T21:52:51.398760Z","shell.execute_reply.started":"2021-10-01T21:52:51.092471Z","shell.execute_reply":"2021-10-01T21:52:51.398132Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"<h2>for this i foun out that using cnn gives best accuracy and coverge in a faster way than if i am using mfcc with ann it is better to use the mean of every row in mfcc</h2>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}